{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kenci.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spireon-ex10/Torrent-To-Google-Drive-Downloader/blob/master/Torrent_To_Google_Drive_Downloader_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CAzKtlWCzjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9834d451-e792-4bf4-89bd-b56e142dbb04"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10T-OJnwd_8b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6hF0emftx4h"
      },
      "source": [
        "# !apt install python3-libtorrent -y\n",
        "# !curl https://rclone.org/install.sh | sudo bash\n",
        "# !add-apt-repository ppa:savoury1/ffmpeg4 -y\n",
        "# !add-apt-repository ppa:savoury1/graphics -y \n",
        "# !add-apt-repository ppa:savoury1/multimedia -y\n",
        "# !apt update\n",
        "# !apt install ffmpeg\n",
        "!apt install -y mediainfo\n",
        "!dpkg --configure -a\n",
        "!apt install mkvtoolnix\n",
        "# !ffmpeg -version\n",
        "# !curl -L https://yt-dl.org/downloads/latest/youtube-dl -o /usr/local/bin/youtube-dl\n",
        "# !chmod a+rx /usr/local/bin/youtube-dl\n",
        "# !apt install lshw\n",
        "# !lshw -short\n",
        "# !curl https://rclone.org/install.sh | sudo bash\n",
        "# !sudo pip3 install -U telegram-upload\n",
        "# !sudo pip3 install twitter-dl\n",
        "# !pip3 install gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvzWkr5d-hcO"
      },
      "source": [
        "!twitter-dl --tweet 1341395488675823616 pv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "2uZL5DS74RbF"
      },
      "source": [
        "m3u8_source = \"https://prod-fastly-ap-northeast-2.video.pscp.tv/Transcoding/v1/hls/buKfDuadQDbabIzQfWgKL5GzAkMC902amMO75zwLBHIG3llwqOv1ANQg6xT_uRbMCl5_Ns90i4H83s-pwRfwkA/transcode/ap-northeast-2/periscope-replay-direct-prod-ap-northeast-2-public/eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCIsInZlcnNpb24iOiIyIn0.eyJFbmNvZGVyU2V0dGluZyI6ImVuY29kZXJfc2V0dGluZ18xMDgwcDMwXzEwIiwiSGVpZ2h0IjoxMDgwLCJLYnBzIjo1NTAwLCJXaWR0aCI6MTkyMH0.OImMZabKYJ0cs9CnIapU-4aBk6KNBiJxi1hh-6l4BZ4/playlist_16837255832593754091.m3u8?type=replay\"  # @param {type:\"string\"}\n",
        "file_name = \"SMTOWN.LIVE.Culture Humanity.1080p.WEB-DL.x264-KENCI.mkv\"  # @param {type:\"string\"}\n",
        "metadata_title = \"SMTOWN LIVE \\\\\\\"Culture Humanity\\\\\\\" - KENCI\"  # @param {type:\"string\"}\n",
        "metadata_comment = \"KENCI\"  # @param {type:\"string\"}\n",
        "sub_url = \"http://meta.video.iqiyi.com/20201126/c2/5e/6ef7c92d520b880b7b04cb90fbab462f.srt?qd_uid=0&qd_tm=1608003520213&qd_tvid=2752732377320900&qyid=429e6b1e2d87c0abe46525947d8b914a&lid=24\" # @param {type:\"string\"}\n",
        "!ffmpeg -i \"$m3u8_source\" -bsf:a aac_adtstoasc -vcodec copy -c copy -crf 20 -metadata title=\"$metadata_title\" -metadata comment=\"$metadata_comment\" $file_name\n",
        "# !wget -O subindo.srt \"$sub_url\"\n",
        "# !mkvmerge -o \"/content/out/$file_name\" --no-subtitles \"/content/$file_name\" --language 0:ind --track-name 0:Indonesian --forced-track 0:yes --default-track 0:yes \"/content/subindo.srt\"\n",
        "# !mkvinfo \"/content/out/$file_name\"\n",
        "# !rm \"/content/$file_name\"\n",
        "# !rm \"/content/subindo.srt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dMPxKCB8b5h"
      },
      "source": [
        "!ffmpeg -i \"/content/Imperfect.Karier.Cinta.dan.Timbangan.2019.1080p.HQ.NF.WEB-DL.x264.AAC.5.1-FLUX5EKA1.mkv\" -r 23.976 -crf 21 -preset fast -c:a aac -ac 2 -b:a 160k -c:v libx265 -pix_fmt yuv420p10le -profile:v main10 -vf scale=1280:720 -metadata title=\"Imperfect: Karir, Cinta & Timbangan (2019) - KENCI\" -metadata comment=\"KENCI\" -metadata:s:v encoder='KULOKENCI' \"/content/Imperfect.Karier.Cinta.dan.Timbangan.2019.720p.10bit.NF.WEB-DL.AAC2.0.x265.HEVC-TeamFLM.mkv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnj_xTJdIVx8"
      },
      "source": [
        "!ffmpeg -i \"https://vuclip-eip2.akamaized.net/c678223620a8a2ce3a1d1c8295cec290/vp63207_V20210207200038/hlsc_e2931_7.m3u8\" -bsf:a aac_adtstoasc -vcodec copy -c copy -crf 50 \"/content/downloads/Mr.Queen.E18.VUI.WEB-DL.mp4\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_pHew3zmVbS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7db255-ae92-49f7-f249-9890d8f6413f"
      },
      "source": [
        "!echo \"Enter m3u8 link:\";read link;echo \"Enter output filename:\";read filename;ffmpeg -i \"$link\" -bsf:a aac_adtstoasc -vcodec copy -c copy -crf 50 $filename.mp4"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter m3u8 link:\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZK5uadEw1awu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a85206-1469-4ebf-a327-c579f14b11f9"
      },
      "source": [
        "# !mkvmerge -o \"/content/out/Attack.on.Titan.S04E01.720p.WEB-DL.x264-KENCI.mkv\" --no-subtitles \"/content/Attack.on.Titan.S04E01.720p.WEB-DL.x264-KENCI.mkv\" --language 0:ind --track-name 0:Indonesian --forced-track 0:yes --default-track 0:yes \"/content/3fe9804f80b74d5abb4275939f9fdc5d.srt\"\n",
        "# !mkvpropedit \"/content/out/Attack.on.Titan.S04E01.720p.WEB-DL.x264-KENCI.mkv\" --edit info --set \"title=Attack on Titan S04E01 - KENCI\"\n",
        "# !mkvinfo \"/content/downloads/Lovestruck.in.the.City.S01E01.720p.NF.WEB-DL.DDP2.0.x265-SH3LBY.mkv\"\n",
        "!mv \"/content/downloads/Move.to.Heaven.S01E06.720p.NF.WEB-DL.DDP5.1.x265-DoA.mkv\" \"/content/downloads/Move.to.Heaven.S01E06.720p.NF.WEB-DL.x265.HEVC-DoA.mkv\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mv: cannot stat '/content/downloads/Vincenzo.S01E20.720p.NF.WEB-DL.DDP2.0.x265-Imagine.mkv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "e0uhRo7cXCzW"
      },
      "source": [
        "#@markdown <center><h3>Add Subtitle</h3></center><br>\n",
        "\n",
        "SERIES_NAME = \"Lovestruck in the City S01E15\" #@param {type:\"string\"}\n",
        "FILE_NAME = \"Lovestruck.in.the.City.S01E15.720p.NF.WEB-DL.x265.HEVC-SH3LBY.mkv\" #@param {type:\"string\"}\n",
        "FILE_MKV_PATH = \"/content/downloads/Lovestruck.in.the.City.S01E15.720p.NF.WEB-DL.DDP2.0.x265-SH3LBY.mkv\" #@param {type:\"string\"}\n",
        "FILE_SRT_PATH = \"/content/ind.ass\" #@param {type:\"string\"}\n",
        " \n",
        "# !mkvmerge -o \"/content/out/temp$FILE_NAME\" --no-subtitles \"$FILE_MKV_PATH\"\n",
        "# !mkvextract tracks \"$FILE_MKV_PATH\" 6:ind.ass\n",
        "# !mkvmerge -o \"/content/out/$FILE_NAME\" --no-subtitles \"$FILE_MKV_PATH\" --language 0:ind --track-name 0:Indonesian --forced-track 0:yes --default-track 0:yes \"$FILE_SRT_PATH\"\n",
        "# !mkvmerge -o \"/content/out/$FILE_NAME\" \"$FILE_MKV_PATH\" --forced-track 6:yes --default-track 6:yes\n",
        "!cp \"$FILE_MKV_PATH\" \"/content/out/$FILE_NAME\"\n",
        "!mkvpropedit \"/content/out/$FILE_NAME\" --edit info --set \"title=$SERIES_NAME - KENCI\" --edit track:8 --set flag-default=1 --edit track:8 --set flag-forced=1\n",
        "# !rm \"/content/out/temp$FILE_NAME\"\n",
        "!mkvinfo \"/content/out/$FILE_NAME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Y-FhrKXR1q0G"
      },
      "source": [
        "SERIES_NAME = \"True Beauty S01E02\" #@param {type:\"string\"}\n",
        "FILE_NAME = \"True.Beauty.S01E02.201210.720p.x265.HEVC-NEXT.mkv\" #@param {type:\"string\"}\n",
        "FILE_MKV_PATH = \"/content/True.Beauty.S01E02.201210.720p.x265.HEVC-NEXT.mkv\" #@param {type:\"string\"}\n",
        " \n",
        "!mv \"$FILE_MKV_PATH\" \"/content/$FILE_NAME\"\n",
        "!mkvpropedit \"/content/$FILE_NAME\" --edit info --set \"title=$SERIES_NAME - KENCI\"\n",
        "!mkvinfo \"/content/$FILE_NAME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSV70H4mX521",
        "cellView": "form"
      },
      "source": [
        "#@markdown <center><h3>Add Subtitle</h3></center><br>\n",
        " \n",
        "SERIES_NAME = \"Run on S01E03\" #@param {type:\"string\"}\n",
        "FILE_NAME = \"Run.on.S01E03.720p.NF.WEB-DL.x265.HEVC-Imagine.mkv\" #@param {type:\"string\"}\n",
        "FILE_MKV_PATH = \"/content/downloads/Run.on.S01E03.720p.NF.WEB-DL.DDP2.0.x265-Imagine.mkv\" #@param {type:\"string\"}\n",
        "FILE_SRT_PATH = \"/content/ind.ass\" #@param {type:\"string\"}\n",
        " \n",
        "# !mkvmerge -o \"/content/out/temp$FILE_NAME\" --no-subtitles \"$FILE_MKV_PATH\"\n",
        "# !mkvextract tracks \"$FILE_MKV_PATH\" 6:ind.ass\n",
        "# !mkvmerge -o \"/content/out/$FILE_NAME\" --no-subtitles \"$FILE_MKV_PATH\" --language 0:ind --track-name 0:Indonesian --forced-track 0:yes --default-track 0:yes \"$FILE_SRT_PATH\"\n",
        "# !mkvmerge -o \"/content/out/$FILE_NAME\" \"$FILE_MKV_PATH\" --forced-track 6:yes --default-track 6:yes\n",
        "!cp \"$FILE_MKV_PATH\" \"/content/out/$FILE_NAME\"\n",
        "!mkvpropedit \"/content/out/$FILE_NAME\" --edit info --set \"title=$SERIES_NAME - KENCI\" --edit track:3 --set flag-default=0 --edit track:6 --set flag-default=0 --edit track:8 --set flag-default=1 --edit track:8 --set flag-forced=1\n",
        "# !rm \"/content/out/temp$FILE_NAME\"\n",
        "!mkvinfo \"/content/out/$FILE_NAME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMb_yE-L2-yf",
        "cellView": "form"
      },
      "source": [
        "#@markdown <center><h3>Add Subtitle</h3></center><br>\n",
        "\n",
        "SERIES_NAME = \"The Uncanny Counter S01E08\" #@param {type:\"string\"}\n",
        "FILE_NAME = \"The.Uncanny.Counter.S01E08.720p.NF.WEB-DL.x265.HEVC-Imagine.mkv\" #@param {type:\"string\"}\n",
        "FILE_MKV_PATH = \"/content/downloads/The.Uncanny.Counter.S01E08.720p.NF.WEB-DL.DDP2.0.x265-Imagine.mkv\" #@param {type:\"string\"}\n",
        "FILE_SRT_PATH = \"/content/ind.ass\" #@param {type:\"string\"}\n",
        " \n",
        "# !mkvmerge -o \"/content/out/temp$FILE_NAME\" --no-subtitles \"$FILE_MKV_PATH\"\n",
        "# !mkvextract tracks \"$FILE_MKV_PATH\" 6:ind.ass\n",
        "# !mkvmerge -o \"/content/out/$FILE_NAME\" --no-subtitles \"$FILE_MKV_PATH\" --language 0:ind --track-name 0:Indonesian --forced-track 0:yes --default-track 0:yes \"$FILE_SRT_PATH\"\n",
        "# !mkvmerge -o \"/content/out/$FILE_NAME\" \"$FILE_MKV_PATH\" --forced-track 6:yes --default-track 6:yes\n",
        "!cp \"$FILE_MKV_PATH\" \"/content/out/$FILE_NAME\"\n",
        "!mkvpropedit \"/content/out/$FILE_NAME\" --edit info --set \"title=$SERIES_NAME - KENCI\" --edit track:3 --set flag-default=0 --edit track:6 --set flag-default=0 --edit track:8 --set flag-default=1 --edit track:8 --set flag-forced=1\n",
        "# !rm \"/content/out/temp$FILE_NAME\"\n",
        "!mkvinfo \"/content/out/$FILE_NAME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vz-r0lo5arUD",
        "cellView": "form"
      },
      "source": [
        "#@markdown <center><h3>Nevertheless [K-Drama] (2021) NETFLIX Version</h3></center><br>\n",
        "import sys, os, urllib.request \n",
        "\n",
        "FILE_PATH = \"/content/downloads/Nevertheless.S01E01.720p.NF.WEB-DL.DDP2.0.x265-DoA.mkv\" #@param {type:\"string\"}\n",
        "COVER_URL = \"https://asianwiki.com/File:Nevertheless-mp001.jpeg\" #@param {type:\"string\"}\n",
        "import re \n",
        " \n",
        "FILE_NEW_NAME = re.sub(r'.DDP2.0.x265-DoA.mkv', '.x265.HEVC-DoA.mkv', FILE_PATH) #re.compile (r'-NEXT.mkv') \n",
        "\n",
        "!wget -c \"$COVER_URL\" -O cover.jpg\n",
        "\n",
        "if not os.path.exists(f\"/content/kulokenci_tags.xml\"):\n",
        "  !wget -c \"https://gist.githubusercontent.com/kulokenci/ffb2d6aea6e0278a723be8f3f1ccc1b5/raw/8c5a1aff144a91349e43e52094a015d83023afd8/kulokenci_tags.xml\" -O kulokenci_tags.xml\n",
        "\n",
        "if os.path.exists(f\"/content/kulokenci_tags.xml\"):\n",
        "  !mkvpropedit \"$FILE_PATH\" --edit info --set \"writing-application=Lavf58.45.100\" --attachment-name \"cover.jpg\" --attachment-mime-type \"image/jpeg\" --add-attachment \"cover.jpg\" --tags track:a:\"/content/kulokenci_tags.xml\"\n",
        "  # !mkvpropedit \"$FILE_PATH\" --edit info --set \"writing-application=Lavf58.45.100\"\n",
        "  # !mkvpropedit \"$FILE_PATH\" --attachment-name \"cover.jpg\" --attachment-mime-type \"image/jpeg\" --add-attachment \"cover.jpg\" \n",
        "  !mv \"$FILE_PATH\" \"$FILE_NEW_NAME\" #.x265.HEVC\n",
        "  print('New Name: ' + FILE_NEW_NAME) \n",
        "  !mediainfo \"$FILE_NEW_NAME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu_2ZZDO3o-G",
        "cellView": "form"
      },
      "source": [
        "#@markdown <center><h3>Rename NEXT Version</h3></center><br>\n",
        " \n",
        "FILE_PATH = \"/content/downloads/Voice.S04E02.210619.720p-NEXT.mkv\" #@param {type:\"string\"}\n",
        "COVER_URL = \"https://asianwiki.com/images/8/86/Voice_4-P1.jpg\" #@param {type:\"string\"}\n",
        "import re \n",
        " \n",
        "if not os.path.exists(f\"/content/kulokenci_tags.xml\"):\n",
        "  !wget -c \"https://gist.githubusercontent.com/kulokenci/ffb2d6aea6e0278a723be8f3f1ccc1b5/raw/8c5a1aff144a91349e43e52094a015d83023afd8/kulokenci_tags.xml\" -O kulokenci_tags.xml\n",
        " \n",
        "FILE_NEW_NAME = re.sub(r'-NEXT.mkv', '.x265.HEVC-NEXT.mkv', FILE_PATH) #re.compile (r'-NEXT.mkv') \n",
        " \n",
        "if os.path.exists(f\"/content/kulokenci_tags.xml\"):\n",
        "  !wget -c \"$COVER_URL\" -O cover.jpg\n",
        "  !mkvpropedit \"$FILE_PATH\" --tags track:a1:\"/content/kulokenci_tags.xml\"\n",
        "  !mkvpropedit \"$FILE_PATH\" --edit info --set \"writing-application=Lavf58.45.100\"\n",
        "  !mkvpropedit \"$FILE_PATH\" --attachment-name \"cover.jpg\" --attachment-mime-type \"image/jpeg\" --add-attachment \"cover.jpg\" \n",
        "  !mv \"$FILE_PATH\" \"$FILE_NEW_NAME\" #.x265.HEVC\n",
        "  # print('New Name: ' + FILE_NEW_NAME) \n",
        "  !mediainfo \"$FILE_NEW_NAME\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "N2_1uWUVnk3g",
        "outputId": "e982086b-3d73-4c2e-a597-b9fe67a26fa2"
      },
      "source": [
        "#@markdown <center><h3>Rename Love Alarm 2</h3></center><br>\n",
        "\n",
        "FILE_PATH = \"/content/downloads/Love.Alarm.S02E06.MULTi.720p.NF.WEB-DL.DDP5.1.x265-Imagine.mkv\" #@param {type:\"string\"}\n",
        "\n",
        "import re \n",
        "\n",
        "FILE_NEW_NAME = re.sub(r'DDP5.1.x265-Imagine', 'x265.HEVC-Imagine', FILE_PATH) #re.compile (r'-NEXT.mkv') \n",
        "!mv \"$FILE_PATH\" \"$FILE_NEW_NAME\" #.x265.HEVC\n",
        "print('New Name: ' + FILE_NEW_NAME)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "New Name: /content/downloads/Love.Alarm.S02E06.MULTi.720p.NF.WEB-DL.x265.HEVC-Imagine.mkv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Doy-NQwW97uv",
        "cellView": "form"
      },
      "source": [
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        ")\n",
        "\n",
        "# Telegram Upload installing\n",
        "if not os.path.exists(\"/usr/local/lib/python3.6/dist-packages/telegram_upload\"):\n",
        "    loadingAn()\n",
        "    print(\"Installing Telegram Upload...\")\n",
        "    runSh('sudo pip3 install -U telegram-upload')\n",
        "    print(\"Telegram Upload is installed.\")\n",
        "    clear_output()\n",
        "\n",
        "#@markdown <center><h3>Telegram Uploader</h3></center><br>\n",
        "FILE_PATH = \"/content/downloads/[YouWatch]River Where the Moon Rises E01-360p.mp4\" #@param {type:\"string\"}\n",
        "!telegram-upload \"$FILE_PATH\" --config \"/content/telegram-upload.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji2VtZI3BcVv"
      },
      "source": [
        "# !apt install rar\n",
        "!rar a Lupin.S01.COMPLETE.FRENCH.720p.10bit.NF.WEBRip.2CH.x265.HEVC-PSA.rar \"/content/drive/Shareddrives/Gedang Drive ~ Series/Lupin S01 COMPLETE FRENCH 720p 10bit NF WEBRip 2CH x265 HEVC-PSA\"\n",
        "# !mv \"/content/Lupin S01 COMPLETE FRENCH 720p 10bit NF WEBRip 2CH x265 HEVC-PSA/Lupin.S01E05.FRENCH.720p.10bit.WEBRip.2CH.x265.HEVC-PSA [crots].mkv\" \"/content/Lupin S01 COMPLETE FRENCH 720p 10bit NF WEBRip 2CH x265 HEVC-PSA/Lupin.S01E05.FRENCH.720p.10bit.WEBRip.2CH.x265.HEVC-PSA.mkv\"\n",
        "# !youtube-dl -o '%(playlist)s/%(playlist_index)s - %(title)s.%(ext)s' -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio' --merge-output-format mkv 'https://www.youtube.com/playlist?list=PLPFJ9mIr8yYAWh2Waq_JwL4voPQHAT18J'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GUNl2S-S2hE"
      },
      "source": [
        "# !zip -9 -r Lupin.S01.COMPLETE.FRENCH.720p.10bit.NF.WEBRip.2CH.x265.HEVC-PSA.zip '/content/drive/Shareddrives/Gedang Drive ~ Series/Lupin S01 COMPLETE FRENCH 720p 10bit NF WEBRip 2CH x265 HEVC-PSA'\n",
        "# !apt install -y aria2\n",
        "!mkvinfo \"/content/downloads/Love.Alarm.S02E01.MULTi.720p.NF.WEB-DL.DDP5.1.x265-Imagine.mkv\"\n",
        "# !mkvextract tracks \"/content/downloads/The.Uncanny.Counter.S01E01.720p.NF.WEB-DL.DDP2.0.x264-Imagine.mkv\" 6:ind.ass\n",
        "# !mkdir Start-Up.S01.720p.NF.WEB-DL.x265.HEVC-KENCI\n",
        "# !mv \"/content/Start-Up.S01E16.720p.NF.WEB-DL.x265.HEVC-KENCI.mkv\" \"/content/Start-Up.S01.720p.NF.WEB-DL.x265.HEVC-KENCI/Start-Up.S01E16.720p.NF.WEB-DL.x265.HEVC-KENCI.mkv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtRS4vQQatfW"
      },
      "source": [
        "INFILE=\"/content/drive/My Drive/Loncat.Kelas.S01E03.1080p.VID.WEB-DL.AAC.X264-WnB.ts\"\n",
        "OUTFILE=\"/content/ex/Loncat.Kelas.S01E03.1080p.VID.WEB-DL.AAC.X264-WnB.mkv\"\n",
        "!ffmpeg \\\n",
        "  -i \"/content/drive/My Drive/Loncat.Kelas.S01E03.1080p.VID.WEB-DL.AAC.X264-WnB.ts\" \\\n",
        "  -f lavfi -i movie=\"/content/drive/My Drive/Loncat.Kelas.S01E03.1080p.VID.WEB-DL.AAC.X264-WnB.ts[out+subcc]\" \\\n",
        "  -map 0 -map 1:s \\\n",
        "  -codec:v libx264 \\\n",
        "  -codec:a copy \\\n",
        "  -codec:s srt \\\n",
        "  -metadata:s:s:0 language=ind \\\n",
        "  \"/content/ex/Loncat.Kelas.S01E03.1080p.VID.WEB-DL.AAC.X264-WnB.mkv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTQ7z5Wj2U0J"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqZNP00_CL-7",
        "cellView": "form"
      },
      "source": [
        "#@markdown <h3>⬅️ Click Here to START server</h3>\n",
        "#@markdown <br><center><img src='http://pic2.orsoon.com/2017/0719/20170719091439708.png' height=\"200\" alt=\"aria2\"/></center>\n",
        "#@markdown <center><h3>aria2<br />The next generation download utility.</h3></center><br>\n",
        "import os, pathlib, zipfile, re\n",
        "import urllib.request\n",
        "from IPython.display import HTML, clear_output\n",
        "\n",
        "#####################################\n",
        "USE_FREE_TOKEN = True  # @param {type:\"boolean\"}\n",
        "# Aria2 Service\n",
        "Aria2_rpc = True  # @param {type:\"boolean\"}\n",
        "Ariang_WEBUI = True  # @param {type:\"boolean\"}\n",
        "\n",
        "TOKEN = \"\"  # @param {type:\"string\"}\n",
        "# OUTPUT_DIR = \"\"  # @param {type:\"string\"}\n",
        "PORT = 8221\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        "    PortForward_wrapper,\n",
        "    CWD,\n",
        "    displayUrl,\n",
        "    findProcess\n",
        ")\n",
        "\n",
        "loadingAn()\n",
        "\n",
        "# Ariang SETUP\n",
        "runSh('apt install -y aria2')\n",
        "pathlib.Path('ariang').mkdir(mode=0o777, exist_ok=True)\n",
        "pathlib.Path('downloads').mkdir(mode=0o777, exist_ok=True)\n",
        "\n",
        "# github latest releases tag define\n",
        "def latestTag(link):\n",
        "  import re\n",
        "  from urllib.request import urlopen\n",
        "  htmlF = urlopen(link+\"/releases/latest\").read().decode('UTF-8')\n",
        "  return re.findall(r'.+\\/tag\\/([.0-9A-Za-z]+)\".+/', htmlF)[0]\n",
        "\n",
        "# Downloading latest version of ariang\n",
        "if not os.path.exists(\"ariang/index.html\"):\n",
        "  BASE_URL = r\"https://github.com/mayswind/AriaNg\"\n",
        "  LATEST_TAG = latestTag(BASE_URL)\n",
        "  urlF = f'{BASE_URL}/releases/download/{LATEST_TAG}/' \\\n",
        "              f'AriaNg-{LATEST_TAG}-AllInOne.zip'\n",
        "  urllib.request.urlretrieve(urlF, 'ariang/new.zip')\n",
        "  with zipfile.ZipFile('ariang/new.zip', 'r') as zip_ref:\n",
        "      zip_ref.extractall('ariang')\n",
        "  try:\n",
        "    pathlib.Path('ariang/new.zip').unlink()\n",
        "  except FileNotFoundError:\n",
        "    pass\n",
        "\n",
        "# START_ARIANG_WEBUI_AND_ARIA2_RPC\n",
        "try:\n",
        "  if not OUTPUT_DIR:\n",
        "    OUTPUT_DIR = f\"downloads/\"\n",
        "  elif not os.path.exists(OUTPUT_DIR):\n",
        "    clear_output()\n",
        "    print(\"Error: Your set path not found! Create path!\")\n",
        "    exx()\n",
        "except:\n",
        "  OUTPUT_DIR = f\"{CWD}/downloads/\"\n",
        "if Aria2_rpc:\n",
        "  if not findProcess(\"aria2c\", \"--enable-rpc\"):\n",
        "    try:\n",
        "      trackers = urllib.request.urlopen(\n",
        "          \"https://trackerslist.com/best_aria2.txt\"\n",
        "      ).read().decode()\n",
        "      cmdC = r\"aria2c --enable-rpc --rpc-listen-port=6800 -D \" \\\n",
        "            fr\"-d {OUTPUT_DIR} \" \\\n",
        "            r\"-j 20 \" \\\n",
        "            r\"-c \" \\\n",
        "            fr\"--bt-tracker={trackers} \" \\\n",
        "            r\"--bt-request-peer-speed-limit=0 \" \\\n",
        "            r\"--bt-max-peers=0 \" \\\n",
        "            r\"--seed-ratio=0.0 \" \\\n",
        "            r\"--max-connection-per-server=10 \" \\\n",
        "            r\"--min-split-size=10M \" \\\n",
        "            r\"--follow-torrent=mem \" \\\n",
        "            r\" &\"\n",
        "      runSh(\n",
        "          cmdC,\n",
        "          shell=True\n",
        "      )\n",
        "    except:\n",
        "      print(\"aria2 rpc not enabling. Try again later!\")\n",
        "\n",
        "# START_SERVER\n",
        "# Ngrok region 'us','eu','ap','au','sa','jp','in'\n",
        "clear_output()\n",
        "PORT_FORWARD = \"ngrok\" #@param [\"ngrok\", \"localhost\"]\n",
        "Server = PortForward_wrapper(\n",
        "    PORT_FORWARD, TOKEN, USE_FREE_TOKEN, [['Aria2_rpc', 6800, 'http'], \n",
        "    ['Ariang', 8221, 'http']], 'jp', \n",
        "    [f\"{HOME}/.ngrok2/aria2.yml\", 5042]\n",
        ")\n",
        "if Aria2_rpc:\n",
        "  data = Server.start('Aria2_rpc', displayB=False)\n",
        "  Host = data['url'][7:] \n",
        "  port = \"80\"\n",
        "  clear_output()\n",
        "if Ariang_WEBUI:\n",
        "  if Aria2_rpc:\n",
        "    filePath = 'ariang/index.html'\n",
        "    with open(filePath, 'r+') as f:\n",
        "      read_data = f.read()\n",
        "      f.seek(0)\n",
        "      f.truncate(0)\n",
        "      read_data = re.sub(r'(rpcHost:\"\\w+.\")|rpcHost:\"\"', \n",
        "                        f'rpcHost:\"{Host}\"', read_data)\n",
        "      read_data = re.sub(r'protocol:\"\\w+.\"', r'protocol:\"ws\"', read_data)\n",
        "      read_data = re.sub(r'rpcPort:\"\\d+.\"', f'rpcPort:\"{port}\"', read_data)\n",
        "      f.write(read_data)\n",
        "  try:\n",
        "    urllib.request.urlopen(f\"http://localhost:{PORT}\")\n",
        "  except:\n",
        "    runSh(f\"python3 -m http.server {PORT} &\", shell=True, cd=\"ariang/\")\n",
        " \n",
        "  data2 = Server.start('Ariang', displayB=False)\n",
        "  displayUrl(data2, pNamU='Ariang : ')\n",
        "\n",
        "if Aria2_rpc:\n",
        "  display(HTML(\"\"\"<style>@import url('https://fonts.googleapis.com/css?family=Source+Code+Pro:200,900');  :root {   --text-color: hsla(210, 50%, 85%, 1);   --shadow-color: hsla(210, 40%, 52%, .4);   --btn-color: hsl(210, 80%, 42%);   --bg-color: #141218; }  * {   box-sizing: border-box; } button { position:relative; padding: 10px 20px;     border: none;   background: none;      font-family: \"Source Code Pro\";   font-weight: 900;font-size: 100%;     color: var(--text-color);      background-color: var(--btn-color);   box-shadow: var(--shadow-color) 2px 2px 22px;   border-radius: 4px;    z-index: 0;overflow: hidden; -webkit-user-select: text;-moz-user-select: text;-ms-user-select: text;user-select: text;}  button:focus {   outline-color: transparent;   box-shadow: var(--btn-color) 2px 2px 22px; }  .right::after, button::after {   content: var(--content);   display: block;   position: absolute;   white-space: nowrap;   padding: 40px 40px;   pointer-events:none; }  button::after{   font-weight: 200;   top: -30px;   left: -20px; }   .right, .left {   position: absolute;   width: 100%;   height: 100%;   top: 0; } .right {   left: 66%; } .left {   right: 66%; } .right::after {   top: -30px;   left: calc(-66% - 20px);      background-color: var(--bg-color);   color:transparent;   transition: transform .4s ease-out;   transform: translate(0, -90%) rotate(0deg) }  button:hover .right::after {   transform: translate(0, -47%) rotate(0deg) }  button .right:hover::after {   transform: translate(0, -50%) rotate(-7deg) }  button .left:hover ~ .right::after {   transform: translate(0, -50%) rotate(7deg) }  /* bubbles */ button::before {   content: '';   pointer-events: none;   opacity: .6;   background:     radial-gradient(circle at 20% 35%,  transparent 0,  transparent 2px, var(--text-color) 3px, var(--text-color) 4px, transparent 4px),     radial-gradient(circle at 75% 44%, transparent 0,  transparent 2px, var(--text-color) 3px, var(--text-color) 4px, transparent 4px),     radial-gradient(circle at 46% 52%, transparent 0, transparent 4px, var(--text-color) 5px, var(--text-color) 6px, transparent 6px);    width: 100%;   height: 300%;   top: 0;   left: 0;   position: absolute;   animation: bubbles 5s linear infinite both; }  @keyframes bubbles {   from {     transform: translate();   }   to {     transform: translate(0, -66.666%);   } }.zui-table {    border: solid 1px #DDEEEE;    border-collapse: collapse;    border-spacing: 0;    font: normal 13px;}.zui-table thead th {    background-color: #DDEFEF;    border: solid 1px #DDEEEE;    color: #0000009e;    padding: 10px;    text-align: left;}.zui-table tbody td {border: solid 1px #effff97a;color: #ffffffd1;    padding: 10px;}</style><center><button><table class=\"zui-table blueBG\"><p>Aria2 rpc config<p><thead>        <tr>            <th>Protocol</th>            <th>Host</th>            <th>Port</th>        </tr>    </thead>    <tbody>        <tr>            <td>WebSocket</td><td>\"\"\"+Host+\"\"\"</td><td>\"\"\"+port+\"\"\"</td></tr></tbody></table><a target=\"_blank\" style=\"text-decoration: none;color: hsla(210, 50%, 85%, 1);font-size: 10px;\" href=\"https://raw.githubusercontent.com/biplobsd/OneClickRun/master/img/aria2RpcConfigSetup.gif\">NB. How to setup this's config. [Click ME]</a></button><center>\"\"\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ZFL2TekoAXTZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda3d313-df10-4fc8-87f1-4adf3fba381e"
      },
      "source": [
        "URL = \"https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\" #@param {type:\"string\"}\n",
        "#@markdown <center><h5>Default output path /content/downloads/</h5></center>\n",
        "OUTPUT_PATH = \"/content/downloads\" #@param {type:\"string\"}\n",
        " \n",
        "import pathlib\n",
        "import shutil\n",
        "import hashlib\n",
        "import requests\n",
        "from urllib.parse import urlparse\n",
        "from os import path, mkdir\n",
        "if not path.exists(\"/root/.ipython/ocr.py\"): \n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        " \n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        " \n",
        "def youtubedlInstall():\n",
        "  if not path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "    cmdC = \"rm -rf /content/sample_data/ && \" \\\n",
        "            \" mkdir -p -m 666 /root/.YouTube-DL/ &&\" \\\n",
        "            \" apt-get install atomicparsley &&\" \\\n",
        "            \" curl -L https://yt-dl.org/downloads/latest/youtube-dl \" \\\n",
        "            \"-o /usr/local/bin/youtube-dl &&\" \\\n",
        "            \" chmod a+rx /usr/local/bin/youtube-dl\"\n",
        "    get_ipython().system_raw(cmdC)\n",
        " \n",
        "def aria2Install():\n",
        "  runSh('apt install -y aria2')\n",
        " \n",
        "def istmd(URL): \n",
        "  link = urlparse(URL)\n",
        "    \n",
        "  #YandexDisk\n",
        "  if link.netloc == \"yadi.sk\":\n",
        "    API_ENDPOINT = 'https://cloud-api.yandex.net/v1/disk/public/resources/' \\\n",
        "                    '?public_key={}&path=/{}&offset={}'\n",
        "    dry = False\n",
        "    def md5sum(file_path):\n",
        "        md5 = hashlib.md5()\n",
        "        with open(file_path, 'rb') as f:\n",
        "            for chunk in iter(lambda: f.read(128 * md5.block_size), b''):\n",
        "                md5.update(chunk)\n",
        "        return md5.hexdigest()\n",
        " \n",
        " \n",
        "    def check_and_download_file(target_path, url, size, checksum):\n",
        "        if path.isfile(target_path):\n",
        "            if size == path.getsize(target_path):\n",
        "                if checksum == md5sum(target_path):\n",
        "                    print('URL {}'.format(url))\n",
        "                    print('skipping correct {}'.format(target_path))\n",
        "                    return\n",
        "        if not dry:\n",
        "            print('URL {}'.format(url))\n",
        "            print('downloading {}'.format(target_path))\n",
        "            runSh(f'aria2c -x 16 -s 16 -k 1M -d {OUTPUT_PATH} {url}', output=True)\n",
        "            # r = requests.get(url, stream=True)\n",
        "            # with open(target_path, 'wb') as f:\n",
        "            #     shutil.copyfileobj(r.raw, f)\n",
        " \n",
        " \n",
        "    def download_path(target_path, public_key, source_path, offset=0):\n",
        "        print('getting \"{}\" at offset {}'.format(source_path, offset))\n",
        "        current_path = path.join(target_path, source_path)\n",
        "        pathlib.Path(current_path).mkdir(parents=True, exist_ok=True)\n",
        "        jsn = requests.get(API_ENDPOINT.format(public_key, source_path, offset)).json()\n",
        "        def try_as_file(j):\n",
        "            if 'file' in j:\n",
        "                file_save_path = path.join(current_path, j['name'])\n",
        "                check_and_download_file(file_save_path, j['file'], j['size'], j['md5'])\n",
        "                return True\n",
        "            return False\n",
        " \n",
        "        # first try to treat the actual json as a single file description\n",
        "        if try_as_file(jsn):\n",
        "            return\n",
        " \n",
        "        # otherwise treat it as a directory\n",
        "        emb = jsn['_embedded']\n",
        "        items = emb['items']\n",
        "        for i in items:\n",
        "            # each item can be a file...\n",
        "            if try_as_file(i):\n",
        "                continue\n",
        "            # ... or a directory\n",
        "            else:\n",
        "                subdir_path = path.join(source_path, i['name'])\n",
        "                download_path(target_path, public_key, subdir_path)\n",
        " \n",
        "        # check if current directory has more items\n",
        "        last = offset + emb['limit']\n",
        "        if last < emb['total']:\n",
        "            download_path(target_path, public_key, source_path, last)\n",
        "    download_path(OUTPUT_PATH, URL, '')\n",
        "    return False  \n",
        "  return URL\n",
        " \n",
        "if not OUTPUT_PATH:\n",
        "  OUTPUT_PATH = \"/content/downloads/\"\n",
        "  \n",
        "if not URL == \"\":\n",
        "  aria2Install()\n",
        "  youtubedlInstall()\n",
        "  try:\n",
        "    mkdir(\"downloads\")\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "  url = istmd(URL)\n",
        "  if url != False:\n",
        "    print('URL {}'.format(URL))\n",
        "    cmdC = f'youtube-dl -o \"{OUTPUT_PATH}/%(title)s.%(ext)s\" {URL} ' \\\n",
        "            '--external-downloader aria2c ' \\\n",
        "            '--external-downloader-args \"-x 16 -s 16 -k 1M\"'\n",
        "    runSh(cmdC, output=True)\n",
        "else:\n",
        "  print(\"Please input url\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "URL https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "[generic] Nevertheless.S01E01.210619.720p-NEXT: Requesting header\n",
            "WARNING: Falling back on generic information extractor.\n",
            "[generic] Nevertheless.S01E01.210619.720p-NEXT: Downloading webpage\n",
            "WARNING: URL could be a direct video link, returning it as such.\n",
            "[download] Destination: /content/downloads/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "\n",
            "06/27 05:58:21 [\u001b[1;32mNOTICE\u001b[0m] Downloading 1 item(s)\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#10 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#9 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#12 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#13 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#15 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#14 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#17 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#16 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#19 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#22 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#11 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#18 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#20 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#21 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n",
            "\n",
            "06/27 05:58:22 [\u001b[1;31mERROR\u001b[0m] CUID#23 - Download aborted. URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "Exception: [AbstractCommand.cc:351] errorCode=29 URI=https://cloud3.send.cm/d/dby4qesl6gosj4l4qf2q5f7c2ehmx3ovndjpqyt2xuw6pmhshttjkznda7ty43tme4t46vdw/Nevertheless.S01E01.210619.720p-NEXT.mkv\n",
            "-> [HttpSkipResponseCommand.cc:231] errorCode=29 The response status is not successful. status=503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H46BfFGaKTUk",
        "cellView": "form"
      },
      "source": [
        "#@markdown <center><h3>Zippyshare Downloader<br />Using Aria2 The next generation download utility.</h3></center><br>\n",
        " \n",
        "URL = \"https://www76.zippyshare.com/v/sPae7SoY/file.html\" #@param {type:\"string\"}\n",
        "#@markdown <center><h5>Default output path /content/downloads/</h5></center>\n",
        "OUTPUT_PATH = \"\" #@param {type:\"string\"}\n",
        " \n",
        "import os\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "import pathlib\n",
        "import shutil\n",
        "import hashlib\n",
        "import argparse\n",
        "import traceback\n",
        "try:\n",
        "    from urllib.parse import unquote\n",
        "except ImportError:\n",
        "    from urllib import unquote\n",
        " \n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from os import path, mkdir\n",
        "if not path.exists(\"/root/.ipython/ocr.py\"): \n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        " \n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "if not OUTPUT_PATH:\n",
        "    os.makedirs(\"downloads\", exist_ok=True)\n",
        "    OUTPUT_PATH = \"downloads\"\n",
        " \n",
        "def youtubedlInstall():\n",
        "  if not path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "    cmdC = \"rm -rf /content/sample_data/ && \" \\\n",
        "            \" mkdir -p -m 666 /root/.YouTube-DL/ &&\" \\\n",
        "            \" apt-get install atomicparsley &&\" \\\n",
        "            \" curl -L https://yt-dl.org/downloads/latest/youtube-dl \" \\\n",
        "            \"-o /usr/local/bin/youtube-dl &&\" \\\n",
        "            \" chmod a+rx /usr/local/bin/youtube-dl\"\n",
        "    get_ipython().system_raw(cmdC)\n",
        " \n",
        "def aria2Install():\n",
        "  runSh('apt install -y aria2')\n",
        " \n",
        "def read_txt(abs):\n",
        "    with open(abs) as f:\n",
        "        return [u.strip() for u in f.readlines()]\n",
        " \n",
        "def decrypt_dlc(abs):\n",
        "    # Thank you, dcrypt owner(s).\n",
        "    url = \"http://dcrypt.it/decrypt/paste\"\n",
        "    r = s.post(url, data={\n",
        "            'content': open(abs)\n",
        "        }\n",
        "    )\n",
        "    r.raise_for_status()\n",
        "    j = json.loads(r.text)\n",
        "    if not j.get('success'):\n",
        "        raise Exception(j)\n",
        "    return j['success']['links']\n",
        " \n",
        "def parse_prefs():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\n",
        "        '-u', '--urls', \n",
        "        nargs='+', required=True,\n",
        "        help='URLs separated by a space or an abs path to a txt file.'\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        '-o', '--output-path',\n",
        "        default='ZS-DL downloads',\n",
        "        help='Abs output directory.'\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        '-ov', '--overwrite',\n",
        "        action='store_true',\n",
        "        help='Overwrite file if already exists.'\n",
        "    )\n",
        "    parser.add_argument(\n",
        "        '-p', '--proxy',\n",
        "        help='HTTPS only. <IP>:<port>.'\n",
        "    )\n",
        "    args = parser.parse_args()\n",
        "    if args.urls[0].endswith('.txt'):\n",
        "        args.urls = read_txt(args.urls[0])\n",
        "    for url in args.urls:\n",
        "        if url.endswith('.dlc'):\n",
        "            print(\"Processing DLC container: \" + url)\n",
        "            try:\n",
        "                args.urls = args.urls + decrypt_dlc(url)\n",
        "            except Exception as e:\n",
        "                err(\"Failed to decrypt DLC container: \" + url)\n",
        "            args.urls.remove(url)\n",
        "            time.sleep(1)\n",
        "    return args\n",
        " \n",
        "def dir_setup():\n",
        "    if not os.path.isdir(cfg.output_path):\n",
        "        os.makedirs(cfg.output_path)\n",
        " \n",
        "def err(txt):\n",
        "    print(txt)\n",
        "    traceback.print_exc()\n",
        "    \n",
        "def set_proxy():\n",
        "    s.proxies.update({'https': 'https://' + cfg.proxy})\n",
        "    \n",
        "def check_url(url):\n",
        "    regex = r'https://www(\\d{1,3}).zippyshare.com/v/([a-zA-Z\\d]{8})/file.html'\n",
        "    match = re.match(regex, url)\n",
        "    if match:\n",
        "        return match.group(1), match.group(2)\n",
        "    raise ValueError(\"Invalid URL: \" + str(url))\n",
        " \n",
        "def extract(url, server, _id):\n",
        "    regex = (\n",
        "        r'document.getElementById\\(\\'dlbutton\\'\\).href = \"/d/[a-zA-Z\\d]{8}/\" '\n",
        "        r'\\+ \\((\\d+) % (\\d+) \\+ (\\d+) % (\\d+)\\) \\+ \"\\/(.+)\";'\n",
        "    )\n",
        "    for _ in range(3):\n",
        "        r = s.get(url)\n",
        "        if r.status_code != 500:\n",
        "            break\n",
        "        time.sleep(1)\n",
        "    r.raise_for_status()\n",
        "    meta = re.search(regex, r.text)\n",
        "    if not meta:\n",
        "        raise Exception('Failed to get file URL. File down or pattern changed.')\n",
        "    num_1 = int(meta.group(1))\n",
        "    num_2 = int(meta.group(2))\n",
        "    num_3 = int(meta.group(3))\n",
        "    num_4 = int(meta.group(4))\n",
        "    final_num = num_1 % num_2 + num_3 % num_4\n",
        "    enc_fname = meta.group(5)\n",
        "    file_url = \"https://www{}.zippyshare.com/d/{}/{}/{}\".format(server, _id, final_num, enc_fname)\n",
        "    return file_url, unquote(enc_fname)\n",
        " \n",
        "def get_file(ref, url):\n",
        "    s.headers.update({\n",
        "        'Range': \"bytes=0-\",\n",
        "        'Referer': ref\n",
        "    })\n",
        "    r = s.get(url, stream=True)\n",
        "    del s.headers['Range']\n",
        "    del s.headers['Referer']\n",
        "    r.raise_for_status()\n",
        "    length = int(r.headers['Content-Length'])\n",
        "    return r, length\n",
        "    \n",
        "def download(ref, url, fname):\n",
        "  # print('URL {}'.format(url))\n",
        "  cmdC = f'youtube-dl -o \"{OUTPUT_PATH}/%(title)s.%(ext)s\" {url} ' \\\n",
        "          '--external-downloader aria2c ' \\\n",
        "          '--external-downloader-args \"-x 16 -s 16 -k 1M\"'\n",
        "  runSh(cmdC, output=True)\n",
        " \n",
        "def main(url):\n",
        "    server, _id = check_url(url)\n",
        "    file_url, fname = extract(url, server, _id)\n",
        "    download(url, file_url, fname)\n",
        " \n",
        " \n",
        "if not URL == \"\":\n",
        "  s = requests.Session()\n",
        "  print(\"\"\"\n",
        "     _____ _____     ____  __\n",
        "    |__   |   __|___|    \\|  |\n",
        "    |   __|__   |___|  |  |  |__\n",
        "    |_____|_____|   |____/|_____|        \n",
        "    \"\"\")\n",
        "  youtubedlInstall()\n",
        "  aria2Install()\n",
        "  main(URL)\n",
        "else:\n",
        "  print(\"Please input url\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "roC2AaPlEm77"
      },
      "source": [
        "#@markdown <center><h3>Racaty Downloader<br />Using Aria2 The next generation download utility.</h3></center><br>\n",
        "\n",
        "URL = \"https://racaty.net/hmuxns3984q2\" #@param {type:\"string\"}\n",
        "#@markdown <center><h5>Default output path /content/downloads/</h5></center>\n",
        "OUTPUT_PATH = \"/content/I\" #@param {type:\"string\"}\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import hashlib\n",
        "import requests\n",
        "import re\n",
        "from urllib.parse import urlparse\n",
        "from urllib.parse import unquote\n",
        "from os import path, mkdir\n",
        "if not path.exists(\"/root/.ipython/ocr.py\"): \n",
        "    from subprocess import run\n",
        "    from shlex import split\n",
        "\n",
        "    shellCmd = \"wget -qq https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py \\\n",
        "                    -O /root/.ipython/ocr.py\"\n",
        "    run(split(shellCmd))\n",
        "from ocr import runSh\n",
        "\n",
        "def youtubedlInstall():\n",
        "  if not path.isfile(\"/usr/local/bin/youtube-dl\"):\n",
        "    cmdC = \"rm -rf /content/sample_data/ && \" \\\n",
        "            \" mkdir -p -m 666 /root/.YouTube-DL/ &&\" \\\n",
        "            \" apt-get install atomicparsley &&\" \\\n",
        "            \" curl -L https://yt-dl.org/downloads/latest/youtube-dl \" \\\n",
        "            \"-o /usr/local/bin/youtube-dl &&\" \\\n",
        "            \" chmod a+rx /usr/local/bin/youtube-dl\"\n",
        "    get_ipython().system_raw(cmdC)\n",
        "\n",
        "def aria2Install():\n",
        "  runSh('apt install -y aria2')\n",
        "\n",
        "def racatydl(url):\n",
        "    LINK_PATTERN = re.compile(r'https?:\\/\\/racaty\\.net\\/([\\w\\d]*)')\n",
        "    URLDL_PATTERN = re.compile(r'id=\"uniqueExpirylink\" href=\"(.*)\">')\n",
        "\n",
        "    if \"racaty.net\" in url:\n",
        "        xx = url\n",
        "        link_match = LINK_PATTERN.match(url)\n",
        "        if not link_match:\n",
        "            print('invalid link')\n",
        "        linkid = re.findall(r\"racaty\\.net\\/([\\w\\d]*)\", xx)\n",
        "        dfields = {'op': 'download2', 'id': linkid[0], 'rand': '', 'referer': '', 'method_free': 'Free+Download', 'method_premium' : ''}\n",
        "        postsdl = requests.post(xx, data = dfields)\n",
        "        info = URLDL_PATTERN.findall(postsdl.text)\n",
        "        rturn = info[0]\n",
        "    else:\n",
        "        rturn = url\n",
        "    return rturn\n",
        "\n",
        "def istmd(URL): \n",
        "  link = urlparse(URL)\n",
        "  if link.netloc == \"yadi.sk\":\n",
        "    API_ENDPOINT = 'https://cloud-api.yandex.net/v1/disk/public/resources/' \\\n",
        "                    '?public_key={}&path=/{}&offset={}'\n",
        "    dry = False\n",
        "    def md5sum(file_path):\n",
        "        md5 = hashlib.md5()\n",
        "        with open(file_path, 'rb') as f:\n",
        "            for chunk in iter(lambda: f.read(128 * md5.block_size), b''):\n",
        "                md5.update(chunk)\n",
        "        return md5.hexdigest()\n",
        "\n",
        "\n",
        "    def check_and_download_file(target_path, url, size, checksum):\n",
        "        if path.isfile(target_path):\n",
        "            if size == path.getsize(target_path):\n",
        "                if checksum == md5sum(target_path):\n",
        "                    print('URL {}'.format(url))\n",
        "                    print('skipping correct {}'.format(target_path))\n",
        "                    return\n",
        "        if not dry:\n",
        "            print('URL {}'.format(url))\n",
        "            print('downloading {}'.format(target_path))\n",
        "            runSh(f'aria2c -x 16 -s 16 -k 1M -d {OUTPUT_PATH} {url}', output=True)\n",
        "\n",
        "    def download_path(target_path, public_key, source_path, offset=0):\n",
        "        print('getting \"{}\" at offset {}'.format(source_path, offset))\n",
        "        current_path = path.join(target_path, source_path)\n",
        "        pathlib.Path(current_path).mkdir(parents=True, exist_ok=True)\n",
        "        jsn = requests.get(API_ENDPOINT.format(public_key, source_path, offset)).json()\n",
        "        def try_as_file(j):\n",
        "            if 'file' in j:\n",
        "                file_save_path = path.join(current_path, j['name'])\n",
        "                check_and_download_file(file_save_path, j['file'], j['size'], j['md5'])\n",
        "                return True\n",
        "            return False\n",
        "        if try_as_file(jsn):\n",
        "            return\n",
        "        emb = jsn['_embedded']\n",
        "        items = emb['items']\n",
        "        for i in items:\n",
        "            if try_as_file(i):\n",
        "                continue\n",
        "            else:\n",
        "                subdir_path = path.join(source_path, i['name'])\n",
        "                download_path(target_path, public_key, subdir_path)\n",
        "        last = offset + emb['limit']\n",
        "        if last < emb['total']:\n",
        "            download_path(target_path, public_key, source_path, last)\n",
        "    download_path(OUTPUT_PATH, URL, '')\n",
        "    return False  \n",
        "  return URL\n",
        "\n",
        "if not OUTPUT_PATH:\n",
        "  OUTPUT_PATH = \"/content/downloads/\"\n",
        "  \n",
        "if not URL == \"\":\n",
        "  aria2Install()\n",
        "  youtubedlInstall()\n",
        "  try:\n",
        "    mkdir(\"downloads\")\n",
        "  except FileExistsError:\n",
        "    pass\n",
        "  rctyd = racatydl(URL)\n",
        "  # file_name = link.split('/')[-1]    \n",
        "  # # print \"Downloading file:%s\"%file_name \n",
        "  # r = requests.get(link, stream = True) \n",
        "  # with open(file_name, 'wb') as f: \n",
        "  #   for chunk in r.iter_content(chunk_size = 1024*1024): \n",
        "  #     if chunk: \n",
        "  #       f.write(chunk) \n",
        "  # cmdC = f'wget {rctyd} -O \"{OUTPUT_PATH}/%(title)s\"'\n",
        "  # runSh(cmdC, output=True)\n",
        "  # print \"%s downloaded!\\n\"%file_name\n",
        "  url = istmd(rctyd)\n",
        "  if url != False:\n",
        "    print('URL {}'.format(rctyd))\n",
        "    cmdC = f'aria2c {rctyd}'\n",
        "    cmdC = f'youtube-dl -o \"{OUTPUT_PATH}/%(title)s\" {rctyd} ' \\\n",
        "            '--external-downloader aria2c ' \\\n",
        "            '--external-downloader-args \"-x 16 -s 16 -k 1M\"'\n",
        "    runSh(cmdC, output=True)\n",
        "else:\n",
        "  print(\"Please input url\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ucn_QzF3v2fq"
      },
      "source": [
        "!mv \"/content/downloads/Move.to.Heaven.S01E02.720p.NF.WEB-DL.DDP5.1.x265-DoA.mkv\" \"/content/downloads/Move.to.Heaven.S01E02.720p.NF.WEB-DL.x265.HEVC-DoA.mkv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkgn2TX49AoM",
        "cellView": "form"
      },
      "source": [
        "import sys, os, urllib.request\n",
        "import time\n",
        "import subprocess\n",
        "import contextlib\n",
        "from IPython.display import clear_output\n",
        "\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    loadingAn,\n",
        ")\n",
        "#@title MEGA public link download\n",
        "URL = \"https://mega.nz/file/mw5SVJKB#-xXXTqSo-0n67Ls_RvCdZlSNqqtQ4to09oplMYDLiJA\" #@param {type:\"string\"}\n",
        "OUTPUT_PATH = \"\" #@param {type:\"string\"}\n",
        "if not OUTPUT_PATH:\n",
        "  os.makedirs(\"downloads\", exist_ok=True)\n",
        "  OUTPUT_PATH = \"downloads\"\n",
        "# MEGAcmd installing\n",
        "if not os.path.exists(\"/usr/bin/mega-cmd\"):\n",
        "    loadingAn()\n",
        "    print(\"Installing MEGA ...\")\n",
        "    runSh('sudo apt-get -y update')\n",
        "    runSh('sudo apt-get -y install libmms0 libc-ares2 libc6 libcrypto++6 libgcc1 libmediainfo0v5 libpcre3 libpcrecpp0v5 libssl1.1 libstdc++6 libzen0v5 zlib1g apt-transport-https')\n",
        "    runSh('sudo curl -sL -o /var/cache/apt/archives/MEGAcmd.deb https://mega.nz/linux/MEGAsync/Debian_9.0/amd64/megacmd-Debian_9.0_amd64.deb', output=True)\n",
        "    runSh('sudo dpkg -i /var/cache/apt/archives/MEGAcmd.deb', output=True)\n",
        "    print(\"MEGA is installed.\")\n",
        "    clear_output()\n",
        "\n",
        "# Unix, Windows and old Macintosh end-of-line\n",
        "newlines = ['\\n', '\\r\\n', '\\r']\n",
        "\n",
        "def unbuffered(proc, stream='stdout'):\n",
        "    stream = getattr(proc, stream)\n",
        "    with contextlib.closing(stream):\n",
        "        while True:\n",
        "            out = []\n",
        "            last = stream.read(1)\n",
        "            # Don't loop forever\n",
        "            if last == '' and proc.poll() is not None:\n",
        "                break\n",
        "            while last not in newlines:\n",
        "                # Don't loop forever\n",
        "                if last == '' and proc.poll() is not None:\n",
        "                    break\n",
        "                out.append(last)\n",
        "                last = stream.read(1)\n",
        "            out = ''.join(out)\n",
        "            yield out\n",
        "\n",
        "\n",
        "def transfare():\n",
        "    import codecs\n",
        "    decoder = codecs.getincrementaldecoder(\"UTF-8\")()\n",
        "    cmd = [\"mega-get\", URL, OUTPUT_PATH, \"--ignore-quota-warn\"]\n",
        "    proc = subprocess.Popen(\n",
        "        cmd,\n",
        "        stdout=subprocess.PIPE,\n",
        "        stderr=subprocess.STDOUT,\n",
        "        # Make all end-of-lines '\\n'\n",
        "        universal_newlines=True,\n",
        "    )\n",
        "    for line in unbuffered(proc):\n",
        "        print(line)\n",
        "        \n",
        "\n",
        "\n",
        "transfare()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2yXpuBtbVEa"
      },
      "source": [
        "!mediainfo \"/content/downloads/Voice.S04E02.210619.720p.x265.HEVC-NEXT.mkv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqKcWHZcYRIA"
      },
      "source": [
        "### Code to download torrent\n",
        "Variable **link** stores the link string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNDxy8sU3Ik0",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "875c1f12-89ee-47bd-c51b-d2211d9a3d93"
      },
      "source": [
        "# ============================= FORM ============================= #\n",
        "# @markdown #### ⬅️ Execute rClone\n",
        " \n",
        "Mode = \"Copy\"  # @param [\"Move\", \"Copy\", \"Sync\", \"Verify\", \"Dedupe\", \"Clean Empty Dirs\", \"Empty Trash\"]\n",
        "Source = \"/content/downloads/Voice.S04E02.210619.720p.x265.HEVC-NEXT.mkv\"  # @param {type:\"string\"}\n",
        "Destination = \"/content/drive/Shareddrives/Tempe Drive/GEDANG BACKUP/Voice 4: Judgment Hour (2021) - Ongoing - 720p x265-NEXT\"  # @param {type:\"string\"}\n",
        "Extra_Arguments = \"\"  # @param {type:\"string\"}\n",
        "COPY_SHARED_FILES = False  # @param{type: \"boolean\"}\n",
        "Compare = \"Size & Checksum\"\n",
        "TRANSFERS, CHECKERS = 20, 20\n",
        "THROTTLE_TPS = True\n",
        "BRIDGE_TRANSFER = False  # @param{type: \"boolean\"}\n",
        "FAST_LIST = False  # @param{type: \"boolean\"}\n",
        "OPTIMIZE_GDRIVE = True\n",
        "SIMPLE_LOG = True\n",
        "RECORD_LOGFILE = False  # @param{type: \"boolean\"}\n",
        "SKIP_NEWER_FILE = False\n",
        "SKIP_EXISTED = False\n",
        "SKIP_UPDATE_MODTIME = False\n",
        "ONE_FILE_SYSTEM = False\n",
        "LOG_LEVEL = \"DEBUG\"\n",
        "SYNC_MODE = \"Delete after transfering\"\n",
        "SYNC_TRACK_RENAME = True\n",
        "DEDUPE_MODE = \"Largest\"\n",
        "USE_TRASH = True\n",
        "DRY_RUN = False  # @param{type: \"boolean\"}\n",
        "# ================================================================ #\n",
        "from os import path as _p\n",
        " \n",
        "if not _p.exists(\"/root/.ipython/rlab_utils.py\"):\n",
        "    from shlex import split as _spl\n",
        "    from subprocess import run\n",
        " \n",
        "    shellCmd = \"wget -qq https://biplobsd.github.io/RLabClone/res/rlab_utils.py \\\n",
        "                    -O /root/.ipython/rlab_utils.py\"\n",
        "    run(_spl(shellCmd))\n",
        " \n",
        "from datetime import datetime as _dt\n",
        "from rlab_utils import (\n",
        "    displayOutput,\n",
        "    checkAvailable,\n",
        "    runSh,\n",
        "    prepareSession,\n",
        "    PATH_RClone_Config,\n",
        "    accessSettingFile,\n",
        "    memGiB,\n",
        ")\n",
        " \n",
        " \n",
        "def populateActionArg():\n",
        "    if Mode == \"Copy\":\n",
        "        actionArg = \"copy\"\n",
        "    elif Mode == \"Sync\":\n",
        "        actionArg = \"sync\"\n",
        "    elif Mode == \"Verify\":\n",
        "        actionArg = \"check\"\n",
        "    elif Mode == \"Dedupe\":\n",
        "        actionArg = \"dedupe largest\"\n",
        "    elif Mode == \"Clean Empty Dirs\":\n",
        "        actionArg = \"rmdirs\"\n",
        "    elif Mode == \"Empty Trash\":\n",
        "        actionArg = \"delete\"\n",
        "    else:\n",
        "        actionArg = \"move\"\n",
        " \n",
        "    return actionArg\n",
        " \n",
        " \n",
        "def populateCompareArg():\n",
        "    if Compare == \"Mod-Time\":\n",
        "        compareArg = \"--ignore-size\"\n",
        "    elif Compare == \"Size\":\n",
        "        compareArg = \"--size-only\"\n",
        "    elif Compare == \"Checksum\":\n",
        "        compareArg = \"-c --ignore-size\"\n",
        "    else:\n",
        "        compareArg = \"-c\"\n",
        " \n",
        "    return compareArg\n",
        " \n",
        " \n",
        "def populateOptimizeGDriveArg():\n",
        "    return (\n",
        "        \"--buffer-size 256M \\\n",
        "            --drive-chunk-size 256M \\\n",
        "                --drive-upload-cutoff 256M \\\n",
        "                    --drive-acknowledge-abuse \\\n",
        "                        --drive-keep-revision-forever\"\n",
        "        if OPTIMIZE_GDRIVE\n",
        "        else \"--buffer-size 128M\"\n",
        "    )\n",
        " \n",
        " \n",
        "def populateGDriveCopyArg():\n",
        "    if BRIDGE_TRANSFER and memGiB() < 13:\n",
        "        global TRANSFERS, CHECKERS\n",
        "        TRANSFERS, CHECKERS = 10, 80\n",
        "    else:\n",
        "        pass\n",
        "    return \"--disable copy\" if BRIDGE_TRANSFER else \"--drive-server-side-across-configs\"\n",
        " \n",
        " \n",
        "def populateStatsArg():\n",
        "    statsArg = \"--stats-one-line --stats=5s\" if SIMPLE_LOG else \"--stats=5s -P\"\n",
        "    if LOG_LEVEL != \"OFF\":\n",
        "        statsArg += \" -v\" if SIMPLE_LOG else \"-vv\"\n",
        "    elif LOG_LEVEL == \"INFO\":\n",
        "        statsArg += \" --log-level INFO\"\n",
        "    elif LOG_LEVEL == \"ERROR\":\n",
        "        statsArg += \" --log-level ERROR\"\n",
        "    else:\n",
        "        statsArg += \" --log-level DEBUG\"\n",
        "    return statsArg\n",
        " \n",
        " \n",
        "def populateSyncModeArg():\n",
        "    if Mode != \"Sync\":\n",
        "        return \"\"\n",
        "    elif SYNC_MODE == \"Delete before transfering\":\n",
        "        syncModeArg = \"--delete-before\"\n",
        "    elif SYNC_MODE == \"Delete after transfering\":\n",
        "        syncModeArg = \"--delete-after\"\n",
        "    else:\n",
        "        syncModeArg = \"--delete-during\"\n",
        "    if SYNC_TRACK_RENAME:\n",
        "        syncModeArg += \" --track-renames\"\n",
        "    return syncModeArg\n",
        " \n",
        " \n",
        "def populateDedupeModeArg():\n",
        "    if DEDUPE_MODE == \"Interactive\":\n",
        "        dedupeModeArg = \"--dedupe-mode interactive\"\n",
        "    elif DEDUPE_MODE == \"Skip\":\n",
        "        dedupeModeArg = \"--dedupe-mode skip\"\n",
        "    elif DEDUPE_MODE == \"First\":\n",
        "        dedupeModeArg = \"--dedupe-mode first\"\n",
        "    elif DEDUPE_MODE == \"Newest\":\n",
        "        dedupeModeArg = \"--dedupe-mode newest\"\n",
        "    elif DEDUPE_MODE == \"Oldest\":\n",
        "        dedupeModeArg = \"--dedupe-mode oldest\"\n",
        "    elif DEDUPE_MODE == \"Rename\":\n",
        "        dedupeModeArg = \"--dedupe-mode rename\"\n",
        "    else:\n",
        "        dedupeModeArg = \"--dedupe-mode largest\"\n",
        " \n",
        "    return dedupeModeArg\n",
        " \n",
        " \n",
        "def generateCmd():\n",
        "    sharedFilesArgs = (\n",
        "        \"--drive-shared-with-me --files-from /content/upload.txt --no-traverse\"\n",
        "        if COPY_SHARED_FILES\n",
        "        else \"\"\n",
        "    )\n",
        " \n",
        "    logFileArg = f\"--log-file /content/rclone_log.txt -vv -P\"\n",
        " \n",
        "    args = [\n",
        "        \"rclone\",\n",
        "        f\"--config {PATH_RClone_Config}/rclone.conf\",\n",
        "        '--user-agent \"Mozilla\"',\n",
        "        populateActionArg(),\n",
        "        f'\"{Source}\"',\n",
        "        f'\"{Destination}\"' if Mode in (\"Move\", \"Copy\", \"Sync\") else \"\",\n",
        "        f\"--transfers {str(TRANSFERS)}\",\n",
        "        f\"--checkers {str(CHECKERS)}\",\n",
        "    ]\n",
        " \n",
        "    if Mode == \"Verify\":\n",
        "        args.append(\"--one-way\")\n",
        "    elif Mode == \"Empty Trash\":\n",
        "        args.append(\"--drive-trashed-only --drive-use-trash=false\")\n",
        "    else:\n",
        "        args.extend(\n",
        "            [\n",
        "                populateGDriveCopyArg(),\n",
        "                populateSyncModeArg(),\n",
        "                populateCompareArg(),\n",
        "                populateOptimizeGDriveArg(),\n",
        "                \"-u\" if SKIP_NEWER_FILE else \"\",\n",
        "                \"--ignore-existing\" if SKIP_EXISTED else \"\",\n",
        "                \"--no-update-modtime\" if SKIP_UPDATE_MODTIME else \"\",\n",
        "                \"--one-file-system\" if ONE_FILE_SYSTEM else \"\",\n",
        "                \"--tpslimit 95 --tpslimit-burst 40\" if THROTTLE_TPS else \"\",\n",
        "                \"--fast-list\" if FAST_LIST else \"\",\n",
        "                \"--delete-empty-src-dirs\" if Mode == \"Move\" else \"\",\n",
        "            ]\n",
        "        )\n",
        "    args.extend(\n",
        "        [\n",
        "            \"-n\" if DRY_RUN else \"\",\n",
        "            populateStatsArg() if not RECORD_LOGFILE else logFileArg,\n",
        "            sharedFilesArgs,\n",
        "            Extra_Arguments,\n",
        "        ]\n",
        "    )\n",
        " \n",
        "    return args\n",
        " \n",
        " \n",
        "def executeRclone():\n",
        "    prepareSession()\n",
        "    if Source.strip() == \"\":\n",
        "        displayOutput(\"❌ The Source field is empty.\")\n",
        "        return\n",
        "    if checkAvailable(\"/content/rclone_log.txt\"):\n",
        "        if not checkAvailable(\"/content/logfiles\"):\n",
        "            runSh(\"mkdir -p -m 666 /content/logfiles\")\n",
        "        job = accessSettingFile(\"job.txt\")\n",
        "        runSh(\n",
        "            f'mv /content/rclone_log.txt /content/logfiles/{job[\"title\"]}_{job[\"status\"]}_logfile.txt'\n",
        "        )\n",
        " \n",
        "    onGoingJob = {\n",
        "        \"title\": f'{Mode}_{Source}_{Destination}_{_dt.now().strftime(\"%a-%H-%M-%S\")}',\n",
        "        \"status\": \"ongoing\",\n",
        "    }\n",
        "    accessSettingFile(\"job.txt\", onGoingJob)\n",
        " \n",
        "    cmd = \" \".join(generateCmd())\n",
        "    runSh(cmd, output=True)\n",
        "    displayOutput(Mode, \"success\")\n",
        " \n",
        "    onGoingJob[\"status\"] = \"finished\"\n",
        "    accessSettingFile(\"job.txt\", onGoingJob)\n",
        " \n",
        "executeRclone()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021/06/21 00:34:15 INFO  : Starting transaction limiter: max 95 transactions/s with burst 40\n",
            "2021/06/21 00:34:20 INFO  : Voice.S04E02.210619.720p.x265.HEVC-NEXT.mkv: Copied (new)\n",
            "2021/06/21 00:34:20 INFO  :   297.005M / 297.005 MBytes, 100%, 90.933 MBytes/s, ETA 0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "            <center>\n",
              "                <h2 style=\"font-family:monospace;color:#28a745;\">\n",
              "                    👍 Operation Copy has been successfully completed.\n",
              "                </h2>\n",
              "                <br>\n",
              "            </center>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2lK-z0dxTbZ"
      },
      "source": [
        "/content/drive/Shareddrives/Tempe Drive/GEDANG BACKUP/Move to Heaven (2021) - 720p NF WEB-DL x265-DoA\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "LotiU5RMlM_W"
      },
      "source": [
        "#@markdown <center><h3>Create/Edit Rclone config</h3>Create a new remote with name, type and options.<br><font size=1px>After created your config file download that. Next time just upload and you are done!</font></center>\n",
        "import os, urllib.request\n",
        "from IPython.display import HTML\n",
        "USE_FREE_TOKEN = True  # @param {type:\"boolean\"}\n",
        "TOKEN = \"\"  # @param {type:\"string\"}\n",
        "REGION = \"JP\" #@param [\"US\", \"EU\", \"AP\", \"AU\", \"SA\", \"JP\", \"IN\"]\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "runW = get_ipython()\n",
        "\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "#####################################\n",
        "\n",
        "if not os.path.exists(\"/root/.ipython/rlab_utils.py\"):\n",
        "  from shlex import split as _spl\n",
        "  from subprocess import run\n",
        "\n",
        "  shellCmd = \"wget -qq https://biplobsd.github.io/RLabClone/res/rlab_utils.py \\\n",
        "                  -O /root/.ipython/rlab_utils.py\"\n",
        "  run(_spl(shellCmd))\n",
        "\n",
        "from rlab_utils import (\n",
        "    prepareSession,\n",
        "    PATH_RClone_Config,\n",
        "    runSh\n",
        ")\n",
        "from ocr import (\n",
        "    PortForward_wrapper\n",
        ")\n",
        "\n",
        "###################################\n",
        "import codecs\n",
        "import contextlib\n",
        "import locale\n",
        "import os\n",
        "import pty\n",
        "import select\n",
        "import signal\n",
        "import subprocess\n",
        "import sys\n",
        "import termios\n",
        "import time\n",
        "\n",
        "\n",
        "from IPython.utils import text\n",
        "import six\n",
        "from google.colab import _ipython\n",
        "from google.colab import _message\n",
        "from google.colab.output import _tags\n",
        "\n",
        "# Linux read(2) limits to 0x7ffff000 so stay under that for clarity.\n",
        "_PTY_READ_MAX_BYTES_FOR_TEST = 2**20  # 1MB\n",
        "\n",
        "_ENCODING = 'UTF-8'\n",
        "\n",
        "class ShellResult(object):\n",
        "  \"\"\"Result of an invocation of the shell magic.\n",
        "\n",
        "  Note: This is intended to mimic subprocess.CompletedProcess, but has slightly\n",
        "  different characteristics, including:\n",
        "    * CompletedProcess has separate stdout/stderr properties. A ShellResult\n",
        "      has a single property containing the merged stdout/stderr stream,\n",
        "      providing compatibility with the existing \"!\" shell magic (which this is\n",
        "      intended to provide an alternative to).\n",
        "    * A custom __repr__ method that returns output. When the magic is invoked as\n",
        "      the only statement in the cell, Python prints the string representation by\n",
        "      default. The existing \"!\" shell magic also returns output.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, args, returncode, command_output):\n",
        "    self.args = args\n",
        "    self.returncode = returncode\n",
        "    self.output = command_output\n",
        "\n",
        "  def check_returncode(self):\n",
        "    if self.returncode:\n",
        "      raise subprocess.CalledProcessError(\n",
        "          returncode=self.returncode, cmd=self.args, output=self.output)\n",
        "\n",
        "  def _repr_pretty_(self, p, cycle):  # pylint:disable=unused-argument\n",
        "    # Note: When invoking the magic and not assigning the result\n",
        "    # (e.g. %shell echo \"foo\"), Python's default semantics will be used and\n",
        "    # print the string representation of the object. By default, this will\n",
        "    # display the __repr__ of ShellResult. Suppress this representation since\n",
        "    # the output of the command has already been displayed to the output window.\n",
        "    if cycle:\n",
        "      raise NotImplementedError\n",
        "\n",
        "\n",
        "def _configure_term_settings(pty_fd):\n",
        "  term_settings = termios.tcgetattr(pty_fd)\n",
        "  # ONLCR transforms NL to CR-NL, which is undesirable. Ensure this is disabled.\n",
        "  # http://man7.org/linux/man-pages/man3/termios.3.html\n",
        "  term_settings[1] &= ~termios.ONLCR\n",
        "\n",
        "  # ECHOCTL echoes control characters, which is undesirable.\n",
        "  term_settings[3] &= ~termios.ECHOCTL\n",
        "\n",
        "  termios.tcsetattr(pty_fd, termios.TCSANOW, term_settings)\n",
        "\n",
        "\n",
        "def _run_command(cmd, clear_streamed_output):\n",
        "  \"\"\"Calls the shell command, forwarding input received on the stdin_socket.\"\"\"\n",
        "  locale_encoding = locale.getpreferredencoding()\n",
        "  if locale_encoding != _ENCODING:\n",
        "    raise NotImplementedError(\n",
        "        'A UTF-8 locale is required. Got {}'.format(locale_encoding))\n",
        "\n",
        "  parent_pty, child_pty = pty.openpty()\n",
        "  _configure_term_settings(child_pty)\n",
        "\n",
        "  epoll = select.epoll()\n",
        "  epoll.register(\n",
        "      parent_pty,\n",
        "      (select.EPOLLIN | select.EPOLLOUT | select.EPOLLHUP | select.EPOLLERR))\n",
        "\n",
        "  try:\n",
        "    temporary_clearer = _tags.temporary if clear_streamed_output else _no_op\n",
        "\n",
        "    with temporary_clearer(), _display_stdin_widget(\n",
        "        delay_millis=500) as update_stdin_widget:\n",
        "      # TODO(b/115531839): Ensure that subprocesses are terminated upon\n",
        "      # interrupt.\n",
        "      p = subprocess.Popen(\n",
        "          cmd,\n",
        "          shell=True,\n",
        "          executable='/bin/bash',\n",
        "          stdout=child_pty,\n",
        "          stdin=child_pty,\n",
        "          stderr=child_pty,\n",
        "          close_fds=True)\n",
        "      # The child PTY is only needed by the spawned process.\n",
        "      os.close(child_pty)\n",
        "\n",
        "      return _monitor_process(parent_pty, epoll, p, cmd, update_stdin_widget)\n",
        "  finally:\n",
        "    epoll.close()\n",
        "    os.close(parent_pty)\n",
        "\n",
        "\n",
        "class _MonitorProcessState(object):\n",
        "\n",
        "  def __init__(self):\n",
        "    self.process_output = six.StringIO()\n",
        "    self.is_pty_still_connected = True\n",
        "\n",
        "\n",
        "def _monitor_process(parent_pty, epoll, p, cmd, update_stdin_widget):\n",
        "  \"\"\"Monitors the given subprocess until it terminates.\"\"\"\n",
        "  state = _MonitorProcessState()\n",
        "\n",
        "  # A single UTF-8 character can span multiple bytes. os.read returns bytes and\n",
        "  # could return a partial byte sequence for a UTF-8 character. Using an\n",
        "  # incremental decoder is incrementally fed input bytes and emits UTF-8\n",
        "  # characters.\n",
        "  decoder = codecs.getincrementaldecoder(_ENCODING)()\n",
        "\n",
        "  num_interrupts = 0\n",
        "  echo_status = None\n",
        "  while True:\n",
        "    try:\n",
        "      result = _poll_process(parent_pty, epoll, p, cmd, decoder, state)\n",
        "      if result is not None:\n",
        "        return result\n",
        "      term_settings = termios.tcgetattr(parent_pty)\n",
        "      new_echo_status = bool(term_settings[3] & termios.ECHO)\n",
        "      if echo_status != new_echo_status:\n",
        "        update_stdin_widget(new_echo_status)\n",
        "        echo_status = new_echo_status\n",
        "    except KeyboardInterrupt:\n",
        "      try:\n",
        "        num_interrupts += 1\n",
        "        if num_interrupts == 1:\n",
        "          p.send_signal(signal.SIGINT)\n",
        "        elif num_interrupts == 2:\n",
        "          # Process isn't responding to SIGINT and user requested another\n",
        "          # interrupt. Attempt to send SIGTERM followed by a SIGKILL if the\n",
        "          # process doesn't respond.\n",
        "          p.send_signal(signal.SIGTERM)\n",
        "          time.sleep(0.5)\n",
        "          if p.poll() is None:\n",
        "            p.send_signal(signal.SIGKILL)\n",
        "      except KeyboardInterrupt:\n",
        "        # Any interrupts that occur during shutdown should not propagate.\n",
        "        pass\n",
        "\n",
        "      if num_interrupts > 2:\n",
        "        # In practice, this shouldn't be possible since\n",
        "        # SIGKILL is quite effective.\n",
        "        raise\n",
        "\n",
        "\n",
        "def _poll_process(parent_pty, epoll, p, cmd, decoder, state):\n",
        "  \"\"\"Polls the process and captures / forwards input and output.\"\"\"\n",
        "\n",
        "  terminated = p.poll() is not None\n",
        "  if terminated:\n",
        "    termios.tcdrain(parent_pty)\n",
        "    # We're no longer interested in write events and only want to consume any\n",
        "    # remaining output from the terminated process. Continuing to watch write\n",
        "    # events may cause early termination of the loop if no output was\n",
        "    # available but the pty was ready for writing.\n",
        "    epoll.modify(parent_pty,\n",
        "                 (select.EPOLLIN | select.EPOLLHUP | select.EPOLLERR))\n",
        "\n",
        "  output_available = False\n",
        "\n",
        "  events = epoll.poll()\n",
        "  input_events = []\n",
        "  for _, event in events:\n",
        "    if event & select.EPOLLIN:\n",
        "      output_available = True\n",
        "      raw_contents = os.read(parent_pty, _PTY_READ_MAX_BYTES_FOR_TEST)\n",
        "      import re\n",
        "      decoded_contents = re.sub(r\"http:\\/\\/127.0.0.1:53682\", Server[\"url\"], \n",
        "                                decoder.decode(raw_contents))\n",
        "      sys.stdout.write(decoded_contents)\n",
        "      state.process_output.write(decoded_contents)\n",
        "\n",
        "    if event & select.EPOLLOUT:\n",
        "      # Queue polling for inputs behind processing output events.\n",
        "      input_events.append(event)\n",
        "\n",
        "    # PTY was disconnected or encountered a connection error. In either case,\n",
        "    # no new output should be made available.\n",
        "    if (event & select.EPOLLHUP) or (event & select.EPOLLERR):\n",
        "      state.is_pty_still_connected = False\n",
        "\n",
        "  for event in input_events:\n",
        "    # Check to see if there is any input on the stdin socket.\n",
        "    # pylint: disable=protected-access\n",
        "    input_line = _message._read_stdin_message()\n",
        "    # pylint: enable=protected-access\n",
        "    if input_line is not None:\n",
        "      # If a very large input or sequence of inputs is available, it's\n",
        "      # possible that the PTY buffer could be filled and this write call\n",
        "      # would block. To work around this, non-blocking writes and keeping\n",
        "      # a list of to-be-written inputs could be used. Empirically, the\n",
        "      # buffer limit is ~12K, which shouldn't be a problem in most\n",
        "      # scenarios. As such, optimizing for simplicity.\n",
        "      input_bytes = bytes(input_line.encode(_ENCODING))\n",
        "      os.write(parent_pty, input_bytes)\n",
        "\n",
        "  # Once the process is terminated, there still may be output to be read from\n",
        "  # the PTY. Wait until the PTY has been disconnected and no more data is\n",
        "  # available for read. Simply waiting for disconnect may be insufficient if\n",
        "  # there is more data made available on the PTY than we consume in a single\n",
        "  # read call.\n",
        "  if terminated and not state.is_pty_still_connected and not output_available:\n",
        "    sys.stdout.flush()\n",
        "    command_output = state.process_output.getvalue()\n",
        "    return ShellResult(cmd, p.returncode, command_output)\n",
        "\n",
        "  if not output_available:\n",
        "    # The PTY is almost continuously available for reading input to provide\n",
        "    # to the underlying subprocess. This means that the polling loop could\n",
        "    # effectively become a tight loop and use a large amount of CPU. Add a\n",
        "    # slight delay to give resources back to the system while monitoring the\n",
        "    # process.\n",
        "    # Skip this delay if we read output in the previous loop so that a partial\n",
        "    # read doesn't unnecessarily sleep before reading more output.\n",
        "    # TODO(b/115527726): Rather than sleep, poll for incoming messages from\n",
        "    # the frontend in the same poll as for the output.\n",
        "    time.sleep(0.1)\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _display_stdin_widget(delay_millis=0):\n",
        "  \"\"\"Context manager that displays a stdin UI widget and hides it upon exit.\n",
        "\n",
        "  Args:\n",
        "    delay_millis: Duration (in milliseconds) to delay showing the widget within\n",
        "      the UI.\n",
        "\n",
        "  Yields:\n",
        "    A callback that can be invoked with a single argument indicating whether\n",
        "    echo is enabled.\n",
        "  \"\"\"\n",
        "  shell = _ipython.get_ipython()\n",
        "  display_args = ['cell_display_stdin', {'delayMillis': delay_millis}]\n",
        "  _message.blocking_request(*display_args, parent=shell.parent_header)\n",
        "\n",
        "  def echo_updater(new_echo_status):\n",
        "    # Note: Updating the echo status uses colab_request / colab_reply on the\n",
        "    # stdin socket. Input provided by the user also sends messages on this\n",
        "    # socket. If user input is provided while the blocking_request call is still\n",
        "    # waiting for a colab_reply, the input will be dropped per\n",
        "    # https://github.com/googlecolab/colabtools/blob/56e4dbec7c4fa09fad51b60feb5c786c69d688c6/google/colab/_message.py#L100.\n",
        "    update_args = ['cell_update_stdin', {'echo': new_echo_status}]\n",
        "    _message.blocking_request(*update_args, parent=shell.parent_header)\n",
        "\n",
        "  yield echo_updater\n",
        "\n",
        "  hide_args = ['cell_remove_stdin', {}]\n",
        "  _message.blocking_request(*hide_args, parent=shell.parent_header)\n",
        "\n",
        "\n",
        "@contextlib.contextmanager\n",
        "def _no_op():\n",
        "  yield\n",
        "\n",
        "###################################\n",
        "prepareSession()\n",
        "\n",
        "PORT_FORWARD = \"localhost\" #@param [\"ngrok\", \"localhost\"]\n",
        "Server = PortForward_wrapper(\n",
        "    PORT_FORWARD, TOKEN, USE_FREE_TOKEN, [['rcloneConfig', 53682, 'http'], \n",
        "                            ['pyload', 8000, 'http']], REGION.lower(), \n",
        "    [f\"{HOME}/.ngrok2/rclonePyload.yml\", 4074]\n",
        ").start('rcloneConfig', displayB=False, v=False)\n",
        "\n",
        "printData = \"\"\"Copy this URL,\n",
        "  It's needed for authentication purposes.\n",
        "  After completing your account select, you redirect to a website, after back\n",
        "  you need to change http://127.0.0.0:53682 to {}\"\"\".format(Server['url'])\n",
        "print(printData)\n",
        "display(HTML('&emsp;&emsp;<a href=\"https://raw.githubusercontent.com/biplobsd/OneClickRun/master/img/rclone_config_create.gif\" target=\"_blank\">See how</a><br><br>'))\n",
        "print(f\"{Server['url']}\", end=\"\\n\\n\")\n",
        "_run_command(f\"rclone config --config {PATH_RClone_Config}/rclone.conf\", False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "EufqSVkck_Xq",
        "outputId": "aece42f2-02d5-4d89-abc4-a21811db9bc4"
      },
      "source": [
        "# ============================= FORM ============================= #\n",
        "# @markdown #### ⬅️ Download config file.\n",
        "MODE = \"RCONFIG\"  # @param ['UTILS', 'RCONFIG']\n",
        "# ================================================================ #\n",
        "from google.colab import files\n",
        "\n",
        "def downloadFile():\n",
        "  if MODE == \"UTILS\":\n",
        "      filePath = \"/root/.ipython/rlab_utils.py\"\n",
        "  elif MODE == \"RCONFIG\":\n",
        "      filePath = f\"{PATH_RClone_Config}/rclone.conf\"\n",
        "  else:\n",
        "      pass\n",
        "  try:\n",
        "    files.download(filePath)\n",
        "  except FileNotFoundError:\n",
        "    print(\"File not found!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  downloadFile()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_8a91bac4-498e-4c24-b109-8eee0a6192aa\", \"rclone.conf\", 17)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "KJ7ntBPN0BYb"
      },
      "source": [
        "# ============================= FORM ============================= #\n",
        "# @markdown #### ⬅️ Extract Files\n",
        "MODE = \"UNZIP\"  # @param [\"UNZIP\", \"UNTAR\", \"UNRAR\", \"7Z\"]\n",
        "PATH_TO_FILE = \"/content/drive/Shareddrives/Tempe Drive/Gedang ~ BOT UPLOAD/PPT Template/42-Business-ppt-template.zip\"  # @param {type:\"string\"}\n",
        "extractPath = \"/content/drive/Shareddrives/TBNH Team - Drive/DATA 1/TEMPLATE PPT\"  # @param {type:\"string\"}\n",
        "ARCHIVE_PASSWORD = \"\" #@param {type:\"string\"}\n",
        "\n",
        "# ================================================================ #\n",
        "import os, urllib.request\n",
        "HOME = os.path.expanduser(\"~\")\n",
        "\n",
        "if not os.path.exists(f\"{HOME}/.ipython/ocr.py\"):\n",
        "    hCode = \"https://raw.githubusercontent.com/biplobsd/\" \\\n",
        "                \"OneClickRun/master/res/ocr.py\"\n",
        "    urllib.request.urlretrieve(hCode, f\"{HOME}/.ipython/ocr.py\")\n",
        "\n",
        "from ocr import (\n",
        "    runSh,\n",
        "    checkAvailable,\n",
        ")\n",
        "\n",
        "def extractFiles():\n",
        "    global extractPath\n",
        "    if ARCHIVE_PASSWORD:\n",
        "      passADD = f'-P {ARCHIVE_PASSWORD}'\n",
        "    else:\n",
        "      passADD = ''\n",
        "    if not extractPath:\n",
        "      extractPath = \"/content/extract\"\n",
        "    os.makedirs(extractPath, exist_ok=True)\n",
        "    if MODE == \"UNZIP\":\n",
        "        runSh('unzip '+passADD+f' \"{PATH_TO_FILE}\" -d \"{extractPath}\"', output=True)\n",
        "    elif MODE == \"UNRAR\":\n",
        "        runSh(f'unrar x \"{PATH_TO_FILE}\" \"{extractPath}\" '+passADD+' -o+', output=True)\n",
        "    elif MODE == \"UNTAR\":\n",
        "        runSh(f'tar -C \"{extractPath}\" -xvf \"{PATH_TO_FILE}\"', output=True)\n",
        "    else:\n",
        "        runSh(f'7z x \"{PATH_TO_FILE}\" -o{extractPath} '+passADD, output=True)\n",
        "\n",
        "\n",
        "extractFiles()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUYwvdbs6rxD"
      },
      "source": [
        "# !unrar x \"/content/drive/Shareddrives/Tempe Drive/TaniMovies_Demon.Slayer.the.Movie.Mugen.Train.2020.720p.WEBRip.Dual-Audio.x265.HEVCBay.rar\" -p\n",
        "!mv \"/content/TaniMovies_Demon.Slayer.the.Movie.Mugen.Train.2020.720p.WEBRip.Dual-Audio.x265.HEVCBay.mkv\" \"/content/Demon.Slayer.the.Movie.Mugen.Train.2020.720p.WEBRip.Dual-Audio.x265.HEVCBay.mkv\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "V6hXgSOkGuhj"
      },
      "source": [
        "# ============================= FORM ============================= #\n",
        "# @markdown #### ⬅️ Archive Files\n",
        "MODE = \"ZIP\" #@param [\"ZIP\", \"TAR\", \"7Z\"]\n",
        "FILENAME = \"Lupin.S01.COMPLETE.FRENCH.720p.10bit.NF.WEBRip.2CH.x265.HEVC-PSA\"  # @param {type:\"string\"}\n",
        "PATH_TO_FILE = \"/content/Lupin S01 COMPLETE FRENCH 720p 10bit NF WEBRip 2CH x265 HEVC-PSA\"  # @param {type:\"string\"}\n",
        "ARCHIVE_PASSWORD = \"\" #@param {type:\"string\"}\n",
        "compress = 5#@param  {type:\"slider\", min:0, max:9, step:0}\n",
        "# ================================================================ #\n",
        "from pathlib import PurePosixPath\n",
        "\n",
        "pathList = PATH_TO_FILE.split()\n",
        "if MODE == \"ZIP\":\n",
        "    if not FILENAME:\n",
        "      FILENAME = \"/content/NEW_FILE.ZIP\"\n",
        "    if ARCHIVE_PASSWORD:\n",
        "      passADD = f'--password \"{ARCHIVE_PASSWORD}\"'\n",
        "    else:\n",
        "      passADD = ''\n",
        "    for part in pathList:\n",
        "      pathdic = PurePosixPath(part)\n",
        "      parent = pathdic.parent\n",
        "      partName = pathdic.parts[-1]\n",
        "      cmd = f'cd {parent} && zip {passADD} -{compress} -v -r -u \"{FILENAME}\" \"{partName}\"'\n",
        "      !$cmd\n",
        "elif MODE == \"TAR\":\n",
        "    if not FILENAME:\n",
        "      FILENAME = \"/content/NEW_FILE\"\n",
        "    cmd = f'GZIP=-{compress} tar -zcvf \"{FILENAME}.tar.gz\" {PATH_TO_FILE}'\n",
        "    !$cmd\n",
        "else:\n",
        "    if not FILENAME:\n",
        "        FILENAME = \"NEW_FILE\"\n",
        "    for part in pathList:\n",
        "      pathdic = PurePosixPath(part)\n",
        "      parent = pathdic.parent\n",
        "      partName = pathdic.parts[-1]\n",
        "      cmd = f'7z a -mx={compress} \"{FILENAME}.7z\" {partName}'\n",
        "      !$cmd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "b09BxnANO2ep"
      },
      "source": [
        "# ============================= FORM ============================= #\n",
        "# @markdown #### ⬅️ Torrent Downloader\n",
        "MAGNET_LINK = \"magnet:?xt=urn:btih:b56053b234263ff76a442c4046b24e7ff4b0cb86&dn=Wonder.Woman.1984.2020.1080p.HMAX.WEBRip.1600MB.DD5.1.x264-GalaxyRG&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969%2Fannounce&tr=udp%3A%2F%2Ftracker.leechers-paradise.org%3A6969%2Fannounce&tr=udp%3A%2F%2F9.rarbg.to%3A2710%2Fannounce&tr=udp%3A%2F%2Ftracker.openbittorrent.com%3A80%2Fannounce&tr=udp%3A%2F%2Fipv4.tracker.harry.lu%3A80%2Fannounce&tr=udp%3A%2F%2Fopen.stealth.si%3A80%2Fannounce&tr=udp%3A%2F%2Ftracker.tiny-vps.com%3A6969%2Fannounce&tr=udp%3A%2F%2Fopen.demonii.si%3A1337%2Fannounce\"  # @param {type:\"string\"}\n",
        "# ================================================================ #\n",
        "\n",
        "import libtorrent as lt\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "ses = lt.session()\n",
        "ses.listen_on(6881, 6891)\n",
        "params = {\n",
        "    'save_path': '/content/dl',\n",
        "    'storage_mode': lt.storage_mode_t(2),\n",
        "    'paused': False,\n",
        "    'auto_managed': True,\n",
        "    'duplicate_is_error': True}\n",
        "link = MAGNET_LINK # PASTE TORRENT/MAGNET LINK HERE\n",
        "print(link)\n",
        "\n",
        "handle = lt.add_magnet_uri(ses, link, params)\n",
        "ses.start_dht()\n",
        "\n",
        "begin = time.time()\n",
        "print(datetime.datetime.now())\n",
        "\n",
        "print ('Downloading Metadata...')\n",
        "while (not handle.has_metadata()):\n",
        "    time.sleep(1)\n",
        "print ('Got Metadata, Starting Torrent Download...')\n",
        "\n",
        "print(\"Starting\", handle.name())\n",
        "\n",
        "while (handle.status().state != lt.torrent_status.seeding):\n",
        "    s = handle.status()\n",
        "    state_str = ['queued', 'checking', 'downloading metadata', \\\n",
        "            'downloading', 'finished', 'seeding', 'allocating']\n",
        "    print ('%.2f%% complete (down: %.1f kb/s up: %.1f kB/s peers: %d) %s ' % \\\n",
        "            (s.progress * 100, s.download_rate / 1000, s.upload_rate / 1000, \\\n",
        "            s.num_peers, state_str[s.state]))\n",
        "    time.sleep(5)\n",
        "\n",
        "end = time.time()\n",
        "print(handle.name(), \"COMPLETE\")\n",
        "\n",
        "print(\"Elapsed Time: \",int((end-begin)//60),\"min :\", int((end-begin)%60), \"sec\")\n",
        "\n",
        "print(datetime.datetime.now())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hbO1_IBfpvR"
      },
      "source": [
        "# !pip3 install -r kenciclonebot/requirements.txt\n",
        "# !apt-get install libmagic-dev\n",
        "# !cd kenciclonebot/ && python3 -m bot\n",
        "!aria2c ftp://tb-1aio:c1b0xn4@ftp.tappingbox.com/sdimage-tbv3-3.03-210306.img.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
